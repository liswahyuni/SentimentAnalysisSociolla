{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1><b>Proyek Analisis Sentimen</b></h1></center>\n",
    "<center><h2><b>Sentimen Review Sociolla</b></h2></center>\n",
    "<center><h3><b>Created by: Lis Wahyuni</b></h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/liswahyuni/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved model and necessary components\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load model and components\n",
    "best_model = load_model('best_model.h5')\n",
    "\n",
    "# Load tokenizer\n",
    "with open('tokenizer.pkl', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "# Load label encoder\n",
    "with open('label_encoder.pkl', 'rb') as handle:\n",
    "    le1 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords\n",
    "stop_words = stopwords.words('indonesian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    # Split into words\n",
    "    words = text.split()\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer, label_encoder):\n",
    "    # Preprocess text\n",
    "    text = preprocess_text(text)\n",
    "    \n",
    "    # Tokenize and pad\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    MAX_LENGTH = 20\n",
    "    padded = pad_sequences(sequence, maxlen=MAX_LENGTH, padding='post')\n",
    "    \n",
    "    # Predict\n",
    "    prediction = model.predict(padded)\n",
    "    predicted_class = label_encoder.inverse_transform([prediction.argmax()])[0]\n",
    "    \n",
    "    # Get probabilities\n",
    "    class_probabilities = {label_encoder.inverse_transform([i])[0]: prediction[0][i] \n",
    "                         for i in range(len(prediction[0]))}\n",
    "    \n",
    "    return predicted_class, class_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'neutral', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le1.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Analysis Results:\n",
      "\n",
      "Original Text: beh aloe vera toner benton sih bagus banget pas autumn winter tinggal negri lembab bgt wajahku kenyal gitu karna emg kulit tuh acne prone skin and combination kalo indo cocok pakenya malem yah\n",
      "After preprocessing: beh aloe vera toner benton sih bagus banget pas autumn winter tinggal negri lembab bgt wajahku kenyal gitu karna emg kulit tuh acne prone skin and combination kalo indo cocok pakenya malem yah\n",
      "Tokenized: [[1, 129, 540, 3, 126, 10, 17, 12, 26, 1, 3217, 206, 13747, 35, 19, 182, 197, 22, 47, 274, 2, 80, 84, 231, 13, 34, 552, 24, 3765, 8, 243, 292, 558]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Raw prediction values: [3.4856144e-05 2.0376385e-05 9.9994481e-01]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted Sentiment: POSITIVE\n",
      "Confidence Scores:\n",
      "- negative: 0.00%\n",
      "- neutral: 0.00%\n",
      "- positive: 99.99%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Original Text: kemasannya jar label warna pink imut nggak suka teksturnya heavy membentuk lapisan kulit meresap pas udah kering tuh kulit dipegang lapisan moisturizer rontokrontok daki layeringnya bingung sih ditimpa face oil sleeping mask sulit lapisannya rontokrontok aromanya nggak suka ga suka wangi lavender intens sih aromanya\n",
      "After preprocessing: kemasannya jar label warna pink imut nggak suka teksturnya heavy membentuk lapisan kulit meresap pas udah kering tuh kulit dipegang lapisan moisturizer rontokrontok daki layeringnya bingung sih ditimpa face oil sleeping mask sulit lapisannya rontokrontok aromanya nggak suka ga suka wangi lavender intens sih aromanya\n",
      "Tokenized: [[382, 359, 1578, 194, 727, 1757, 99, 16, 14, 394, 3376, 1529, 2, 71, 26, 27, 76, 80, 2, 1474, 1529, 54, 2254, 3072, 3723, 450, 10, 815, 357, 542, 2267, 1019, 1251, 3724, 2254, 380, 99, 16, 4, 16, 171, 2943, 3377, 10, 380]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Raw prediction values: [9.7826946e-01 8.6134431e-05 2.1644285e-02]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Predicted Sentiment: NEGATIVE\n",
      "Confidence Scores:\n",
      "- negative: 97.83%\n",
      "- neutral: 0.01%\n",
      "- positive: 2.16%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Original Text: kasih review guys launching udh exited produknya wardah biru udh oranye btw\n",
      "After preprocessing: kasih review guys launching udh exited produknya wardah biru udh oranye btw\n",
      "Tokenized: [[358, 150, 466, 2274, 101, 4432, 108, 148, 609, 101, 4781, 514]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Raw prediction values: [3.4114120e-05 9.9659157e-01 3.3743621e-03]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Predicted Sentiment: NEUTRAL\n",
      "Confidence Scores:\n",
      "- negative: 0.00%\n",
      "- neutral: 99.66%\n",
      "- positive: 0.34%\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with explicit examples\n",
    "test_reviews = [\n",
    "    \"beh aloe vera toner benton sih bagus banget pas autumn winter tinggal negri lembab bgt wajahku kenyal gitu karna emg kulit tuh acne prone skin and combination kalo indo cocok pakenya malem yah\",\n",
    "    \"kemasannya jar label warna pink imut nggak suka teksturnya heavy membentuk lapisan kulit meresap pas udah kering tuh kulit dipegang lapisan moisturizer rontokrontok daki layeringnya bingung sih ditimpa face oil sleeping mask sulit lapisannya rontokrontok aromanya nggak suka ga suka wangi lavender intens sih aromanya\",\n",
    "    \"kasih review guys launching udh exited produknya wardah biru udh oranye btw\"\n",
    "]\n",
    "\n",
    "print(\"Detailed Analysis Results:\\n\")\n",
    "for text in test_reviews:\n",
    "    # Show each step of processing\n",
    "    print(f\"Original Text: {text}\")\n",
    "    processed_text = preprocess_text(text)\n",
    "    print(f\"After preprocessing: {processed_text}\")\n",
    "    \n",
    "    # Show tokenization result\n",
    "    sequence = tokenizer.texts_to_sequences([processed_text])\n",
    "    print(f\"Tokenized: {sequence}\")\n",
    "    \n",
    "    # Show prediction details\n",
    "    padded = pad_sequences(sequence, maxlen=20, padding='post')\n",
    "    raw_prediction = best_model.predict(padded)\n",
    "    print(f\"Raw prediction values: {raw_prediction[0]}\")\n",
    "    \n",
    "    # Final prediction\n",
    "    sentiment, probabilities = predict_sentiment(text, best_model, tokenizer, le1)\n",
    "    print(f\"Predicted Sentiment: {sentiment.upper()}\")\n",
    "    print(\"Confidence Scores:\")\n",
    "    for class_name, prob in probabilities.items():\n",
    "        print(f\"- {class_name}: {prob:.2%}\")\n",
    "    print(\"-\" * 80 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
